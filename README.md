# Seq2Seq Share Forecasting with Attention Mechanism

## ğŸ“– Overview

This project is an advanced time series forecasting system for **Brand Market Share Prediction**. It combines Granger causality analysis, forward-shift exogenous variable processing, and Attention-based Seq2Seq models to provide accurate future predictions.

### ğŸ¯ Key Features
- **Automatic Schema Recognition**: Automatically detects date, share target, and exogenous variable columns
- **Granger Causality Analysis**: Statistically validates significant lag effects of exogenous variables
- **Forward-shift + Tail-ARIMA**: Generates lag variables considering future impacts
- **Dual Architecture**: Compares Softmax vs Sum-Normalization regularization approaches
- **Attention Seq2Seq**: LSTM-based encoder-decoder with Additive Attention mechanism
- **Future Scenario Forecasting**: Extends monthly predictions up to December 2026

## ğŸ—ï¸ System Architecture

### 1. Data Processing Pipeline
```
Raw Data â†’ Schema Detection â†’ Logit Transform â†’ Granger Test â†’ Lag Generation â†’ Sequence Building
```

### 2. Model Structure
```
Encoder (LSTM) â†’ Context Vector â†’ Decoder (LSTM) â†’ Attention â†’ Dense Layers â†’ Output
```

## ğŸ”§ Installation & Requirements

### Required Libraries
```bash
pip install tensorflow pandas numpy matplotlib statsmodels tqdm openpyxl
```

### Environment Requirements
- Python 3.7+
- TensorFlow 2.x
- Google Colab or local environment

## ğŸ“Š Data Format

### Input Data Structure
The Excel file should follow this format:

```
| Year | Month | Brand1_Share | Brand2_Share | ExogVar1 | ExogVar2 |
|------|-------|--------------|--------------|----------|----------|
| 2019 | 1     | 0.35         | 0.25         | 1000     | 50       |
| 2019 | 2     | 0.37         | 0.23         | 1050     | 52       |
```

**Alternative Date Format:**
```
| Date       | Brand1_Share | Brand2_Share | ExogVar1 | ExogVar2 |
|------------|--------------|--------------|----------|----------|
| 2019-01-01 | 0.35         | 0.25         | 1000     | 50       |
| 2019-02-01 | 0.37         | 0.23         | 1050     | 52       |
```

### Column Requirements
- **Date Columns**: `Year/Month` or `Date` (case-insensitive)
- **Target Columns**: Column names ending with "Share" (case-insensitive)
- **Exogenous Variables**: Any numeric columns excluding date and share columns

## ğŸš€ Usage

### 1. Setup Paths
```python
IN_XLSX   = "/path/to/your/data.xlsx"     # Input Excel file
OUT_DIR   = "/path/to/output/directory"   # Output directory
```

### 2. Run the Complete Pipeline
```python
# Share Forecast (Seq2Seq + Attention)

## ì„¤ì¹˜
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install -r requirements.txt

## ì‹¤í–‰
python seq2seq_share_forecast.py --input "/ì ˆëŒ€/ê²½ë¡œ/sampledata.xlsx" --out_dir "./out" --gif

ì˜µì…˜:
--sheet 0              # ì—‘ì…€ ì‹œíŠ¸ ì¸ë±ìŠ¤
--test_start 2023-01-01
--forecast_end 2026-12-01
--K 6 --H 3            # ì‹œí€€ìŠ¤ ê¸¸ì´
--epochs 30            # ì¡°ê¸°ì¢…ë£Œ í¬í•¨
--gif                  # ë¸Œëœë“œë³„ Actual vs Pred GIF ìƒì„±
```

### 3. Key Parameters
```python
# Time periods
TRAIN_START = pd.Timestamp("2019-01-01")  # Training start
TEST_START  = pd.Timestamp("2023-01-01")  # Test/comparison start
FORECAST_END = pd.Timestamp("2026-12-01") # Forecast end

# Model hyperparameters
K, H = 6, 3  # Encoder length (6 months) / Decoder horizon (3 months)
MAX_LAG = 6  # Maximum lag for Granger causality test
P_THRESH = 0.05  # P-value threshold for significance
```

## ğŸ”¬ Methodology

### 1. Data Preprocessing
- **Logit Transformation**: Converts share ratios (0-1) to unbounded space
- **Log Transformation**: Applied to exogenous variables for stability
- **Clipping**: Ensures share values stay within [Îµ, 1-Îµ] bounds

### 2. Granger Causality Testing
```python
# Tests if exogenous variables Granger-cause share variables
# Finds optimal lag (1-6) with minimum p-value < 0.05
grangercausalitytests(data, lag, verbose=False)
```

### 3. Forward-Shift Lag Variables
- Creates future-looking lag variables: `X(t+lag) â†’ X_lag(t)`
- Uses ARIMA(1,0,1) to fill the tail gap for the last `lag` periods
- Accounts for forward-looking market influences

### 4. Sequence Generation
```python
# Encoder input: [exog_vars + share_logit] for K timesteps
# Decoder input: [prev_share + prev_exog] for H timesteps  
# Target output: [future_share] for H timesteps
```

### 5. Model Architecture

#### Encoder-Decoder with Attention
```python
# Encoder: LSTM(units) â†’ hidden states
# Decoder: LSTM(units) + initial_state from encoder
# Attention: AdditiveAttention between decoder and encoder states
# Output: TimeDistributed Dense layers
```

#### Dual Normalization Approaches
- **Softmax**: `softmax(logits)` with Categorical Crossentropy loss
- **Sum-Normalization**: `ReLU(logits) / sum(ReLU(logits))` with MSE loss

### 6. Grid Search Optimization
```python
GRID = [
    {"units": 32, "batch_size": 16, "learning_rate": 5e-4},
    {"units": 64, "batch_size": 16, "learning_rate": 5e-4},
    {"units": 32, "batch_size": 32, "learning_rate": 5e-4},
    {"units": 64, "batch_size": 32, "learning_rate": 5e-4},
]
```

### 7. Future Scenario Generation
- Simulates exogenous variables using SARIMAX(1,d,1)(0,1,1,12)
- Applies forward-shift transformations to simulated values
- Performs step-by-step decoder inference for extended forecasting

## ğŸ“ˆ Output Files

### Excel Sheets Generated
1. **`granger_lag`**: Granger causality test results with optimal lags
2. **`forecast_soft`**: Future predictions using Softmax normalization
3. **`forecast_sumnorm`**: Future predictions using Sum-normalization
4. **`compare_2023_plus`**: Comparison of predictions vs actual values (2023+)
5. **`metrics`**: Accuracy metrics (RMSE, MAE, MAPE, sMAPE, MASE) for both models

### Visualization
- **`error_panel.png`**: Monthly average absolute error comparison chart

## ğŸ“Š Evaluation Metrics

### Accuracy Measures
- **RMSE**: Root Mean Square Error
- **MAE**: Mean Absolute Error  
- **MAPE**: Mean Absolute Percentage Error
- **sMAPE**: Symmetric Mean Absolute Percentage Error
- **MASE**: Mean Absolute Scaled Error (using seasonal naive as baseline)

### Share-Specific Metrics
- **JS Divergence**: Jensen-Shannon divergence for probability distribution comparison
- **Brand-wise RMSE**: Individual RMSE for each brand

## ğŸ› ï¸ Technical Implementation Details

### Memory Management
- Uses `float32` precision throughout to optimize memory usage
- Implements `dtype(object)` removal to prevent mixed-type issues
- Applies efficient numpy array operations

### Robustness Features
- **Exception Handling**: Graceful fallback for ARIMA fitting failures
- **Data Validation**: Automatic detection and correction of data inconsistencies  
- **Progress Tracking**: tqdm progress bars for long-running operations
- **Early Stopping**: Prevents overfitting with validation-based callbacks

### Scalability Considerations
- Configurable sequence lengths (K, H)
- Flexible exogenous variable handling (automatic pass if none available)
- Grid search with early termination for efficiency

## ğŸ” Model Selection Logic

### Exogenous Variable Usage Priority
1. **Significant Lag Variables**: If Granger causality tests find significant lags
2. **Original Exogenous Variables**: If no significant lags but exogenous data exists
3. **Share-Only Model**: If no exogenous variables available

### Architecture Comparison
- **Softmax**: Better for cases where shares represent true probabilities
- **Sum-Normalization**: More robust for noisy data with potential negative influences

## âš ï¸ Important Notes

### Data Requirements
- Minimum 8 observations for ARIMA tail-filling
- Monthly frequency data expected
- Share values should be in [0, 1] range
- Missing values are forward-filled automatically

### Limitations
- Forward-shift assumption may not hold for all markets
- LSTM performance depends on sufficient training data
- Seasonal patterns require at least 2+ years of historical data

# ì°¸ê³ ) Colab ì‹¤í–‰ ì‹œ
# Colab Quickstart (git clone)

ì´ ë…¸íŠ¸ë¶ ê°€ì´ë“œëŠ” Google Colabì—ì„œ **git clone â†’ ì‹¤í–‰ â†’ ê²°ê³¼ í™•ì¸**ê¹Œì§€ í•œ ë²ˆì— ì§„í–‰í•¨

## 0) ëŸ°íƒ€ì„ ì¤€ë¹„
- (ì„ íƒ) ëŸ°íƒ€ì„ â†’ í•˜ë“œì›¨ì–´ ê°€ì†ê¸°: **GPU**
- ìƒˆ ë…¸íŠ¸ë¶ì—ì„œ ì•„ë˜ ì…€ë“¤ì„ **ìˆœì„œëŒ€ë¡œ** ì‹¤í–‰

## 1) í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜

```python
!pip -q install numpy pandas matplotlib tqdm statsmodels openpyxl pillow tensorflow
import tensorflow as tf, pandas as pd, os, pathlib
print("TensorFlow:", tf.__version__)
```

## 2) Google Drive ë§ˆìš´íŠ¸ & ë°ì´í„° ê²½ë¡œ ì„¤ì •

```python
from google.colab import drive
drive.mount('/content/drive')

# ì…ë ¥ ì—‘ì…€ ê²½ë¡œ (ì˜ˆì‹œ)
DATA = "/content/drive/MyDrive/sampledata.xlsx"  # â† ë³¸ì¸ íŒŒì¼ ê²½ë¡œë¡œ ë³€ê²½ ê°€ëŠ¥
print("DATA exists? =>", os.path.exists(DATA))
assert os.path.exists(DATA), "âŒ ì…ë ¥ ì—‘ì…€ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”."
```

### ë°ì´í„° ìš”ê±´
- **ë‚ ì§œ**: `date`(YYYY-MM) ë˜ëŠ” `Year`+`Month` ì¤‘ í•˜ë‚˜
- **íƒ€ê¹ƒ**: ì»¬ëŸ¼ëª…ì´ `Share`ë¡œ ëë‚˜ëŠ” ëª¨ë“  ì—´ ìë™ ì¸ì‹ (í•© 100/1/ì„ì˜ ìŠ¤ì¼€ì¼ ìë™ ì •ê·œí™”)
- **ì™¸ìƒë³€ìˆ˜**: ì„ íƒ (ì—†ìœ¼ë©´ Granger ë‹¨ê³„ ìë™ íŒ¨ìŠ¤)

## 3) ê¹ƒí—ˆë¸Œì—ì„œ ìŠ¤í¬ë¦½íŠ¸ ë°›ê¸° (git clone)

```python
!rm -rf seq2seq_softmax
!git clone https://github.com/jay-lay-down/seq2seq_softmax.git
%cd seq2seq_softmax
!ls -al
```

## 4) ì‹¤í–‰

```python
!python seq2seq_share_forecast.py \
  --input "$DATA" \
  --out_dir "./out" \
  --test_start "2023-01-01" \
  --forecast_end "2026-12-01" \
  --K 6 --H 3 --epochs 20 \
  --gif
```

- `--gif`ë¥¼ ë¹¼ë©´ GIF ë¯¸ìƒì„± (í•™ìŠµÂ·ë¦¬í¬íŠ¸ëŠ” ë™ì¼)
- ì—í­ ë¡œê·¸ê°€ **ì½˜ì†”ì— ë°”ë¡œ í‘œì‹œ**ë¨ (EarlyStopping í¬í•¨)

## 5) ê²°ê³¼ í™•ì¸

```python
# ì‚°ì¶œë¬¼ ëª©ë¡
!ls -al out
!ls -al out/figures_dual_bar

# ì—‘ì…€ ìš”ì•½ í™•ì¸
xls_path = "out/seq2seq_dual_bar.xlsx"
assert os.path.exists(xls_path), "âŒ out/seq2seq_dual_bar.xlsx ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

xls = pd.ExcelFile(xls_path)
print("sheets:", xls.sheet_names)

# ì§€í‘œ ë° ë¹„êµí‘œ ë¯¸ë¦¬ë³´ê¸°
display(pd.read_excel(xls, "metrics").head())
display(pd.read_excel(xls, "compare_2023_plus").head())
```

### ì˜¤ì°¨ íŒ¨ë„ PNG

```python
from IPython.display import Image, display
display(Image(filename="out/figures_dual_bar/error_panel.png"))
```

### ë¸Œëœë“œë³„ GIF (ì˜µì…˜ `--gif` ì‚¬ìš© ì‹œ)

```python
!ls -al out/figures_dual_bar | grep '.gif' || echo "No GIF (ì˜µì…˜ --gifë¥¼ ì‚¬ìš©í•˜ì„¸ìš”)"
```

## ì˜µì…˜/íŒŒë¼ë¯¸í„°

- `--sheet 0`: ì—‘ì…€ ì‹œíŠ¸ ì¸ë±ìŠ¤
- `--K 6`, `--H 3`: ì¸ì½”ë”/ë””ì½”ë” ìœˆë„ ê¸¸ì´(ì›” ë‹¨ìœ„)
- `--test_start 2023-01-01`: í‰ê°€ ì‹œì‘ ê¸°ì¤€ì›” (í•™ìŠµ ìœˆë„ ê³ ë ¤í•´ ìë™ ì¡°ì •)
- `--forecast_end 2026-12-01`: ì˜ˆì¸¡ ì¢…ë£Œì›”
- `--epochs 30`: ìµœì¢… í•™ìŠµ epoch (EarlyStopping í¬í•¨)
- `--gif`: ì‹¤ì œ vs ì˜ˆì¸¡ GIF ìƒì„±

## ì‚°ì¶œë¬¼ ì„¤ëª…

### `out/seq2seq_dual_bar.xlsx`
- `compare_2023_plus`: **2023-01 ì´í›„** ì‹¤ì œ vs ì˜ˆì¸¡(softmax / sumnorm)
- `forecast_soft`, `forecast_sumnorm`: ë°ì´í„° ë§ˆì§€ë§‰ì›” ì´í›„ **2026-12**ê¹Œì§€ ì˜ˆì¸¡
- `metrics`: RMSE/MAE/MAPE/sMAPE/MASE (softmax vs sumnorm)
- `granger_lag`: ìœ ì˜ë¯¸í•œ Granger ê²°ê³¼ ë˜ëŠ” `no_exog_or_no_significant_granger`

### `out/figures_dual_bar/`
- `error_panel.png`: ì›”ë³„ í‰ê·  ì ˆëŒ€ì˜¤ì°¨(ë¸Œëœë“œ í‰ê· )
- `*.gif`: ë¸Œëœë“œë³„ ì‹¤ì œ vs ì˜ˆì¸¡ íƒ€ì„ë¼ì¸(ì˜µì…˜)

## íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

- **`DATA exists? => False`**: Drive ê²½ë¡œê°€ í‹€ë¦¼. ì‹¤ì œ íŒŒì¼ ìœ„ì¹˜ë¡œ ìˆ˜ì • í•„ìš”
- **íƒ€ê¹ƒ ì—†ìŒ ì˜¤ë¥˜**: íƒ€ê¹ƒ ì—´ ì´ë¦„ì´ ë°˜ë“œì‹œ `...Share`ë¡œ ëë‚˜ì•¼ ìë™ ì¸ì‹ë¨
- **ë‚ ì§œ ì¸ì‹ ì‹¤íŒ¨**: `date`(YYYY-MM) ë˜ëŠ” `Year`+`Month` ì¤‘ í•˜ë‚˜ê°€ í•„ìš”
- **TF retracing ê²½ê³ **: ê¸°ëŠ¥ìƒ ì˜í–¥ ê±°ì˜ ì—†ìŒ. ë¬´ì‹œí•´ë„ ë¨
- **ë©”ëª¨ë¦¬ ë¶€ì¡±**: `--epochs`ë¥¼ ì¤„ì´ê±°ë‚˜ `--K/--H`ë¥¼ ì¶•ì†Œ

## ğŸ“„ License

MIT License - see LICENSE file for details.

## ğŸ‘¤ Author

**Jihee Cho**  
Email: chubbyfinger1010@gmail.com

---

**Last Updated**: September 2025  
**Model Version**: Seq2Seq-Attention-v1.0
